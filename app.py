import os
import openai
import speech_recognition as sr
from flask import Flask, render_template, request, jsonify
from dotenv import load_dotenv
from gtts import gTTS
import uuid
from pydub import AudioSegment
import tempfile
import json
import shutil

# Configurar ffmpeg autom치ticamente si existe en el sistema
AudioSegment.converter = shutil.which("ffmpeg")

# 1. CARGA DE CONFIGURACI칍N
load_dotenv()
openai.api_key = os.environ.get("DEEPSEEK_API_KEY")
openai.api_base = "https://api.deepseek.com/v1"

app = Flask(__name__)
os.makedirs("static/audio", exist_ok=True)

AUDIO_DIR = os.path.join("static", "audio")
os.makedirs(AUDIO_DIR, exist_ok=True)

# 2. TUS DATOS (Im치genes y Respuestas)
imagenes_fijas = {
    "vocales": ["/static/img/a.png", "/static/img/e.png", "/static/img/i.png", "/static/img/o.png", "/static/img/u.png"],
    "abecedario": ["/static/img/a.png", "/static/img/b.png", "/static/img/c.png", "/static/img/d.png", "/static/img/e.png", "/static/img/f.png", "/static/img/g.png", "/static/img/h.png", "/static/img/i.png", "/static/img/j.png", "/static/img/k.png", "/static/img/l.png", "/static/img/m.png", "/static/img/n.png", "/static/img/침.png", "/static/img/o.png", "/static/img/p.png", "/static/img/q.png", "/static/img/r.png", "/static/img/s.png", "/static/img/t.png", "/static/img/u.png", "/static/img/v.png", "/static/img/w.png", "/static/img/x.png", "/static/img/y.png", "/static/img/z.png"],
    "colores": ["/static/img/rojo.png", "/static/img/azul.png", "/static/img/verde.png", "/static/img/amarillo.png", "/static/img/naranja.png", "/static/img/morado.png"],
    "n칰meros": ["/static/img/1.png", "/static/img/2.png", "/static/img/3.png", "/static/img/4.png", "/static/img/5.png", "/static/img/6.png", "/static/img/7.png", "/static/img/8.png", "/static/img/9.png", "/static/img/10.png"],
    "animales": ["/static/img/perro.png", "/static/img/gato.png", "/static/img/elefante.png", "/static/img/leon.png", "/static/img/jirafa.png"],
    "frutas": ["/static/img/manzana.png", "/static/img/platano.png", "/static/img/uva.png", "/static/img/fresa.png", "/static/img/sandia.png"],
    "formas": ["/static/img/circulo.png", "/static/img/cuadrado.png", "/static/img/triangulo.png", "/static/img/rectangulo.png"]
}

respuestas_fijas = {
    "vocales": {"texto": "las vocales son A, E, I, O, U", "audio": "static/audio/vocales.mp3", "imagenes": imagenes_fijas["vocales"]},
    "abecedario": {"texto": "Hola, el abecedario es A, B, C, D, E, F, G, H, I, J, K, L, M, N, 칌, O, P, Q, R, S, T, U, V, W, X, Y, Z", "audio": "static/audio/abecedario.mp3", "imagenes": imagenes_fijas["abecedario"]},
    "colores": {"texto": "Hola, los colores son rojo, azul, verde, amarillo, naranja, morado", "audio": "static/audio/colores.mp3", "imagenes": imagenes_fijas["colores"]},
    "n칰meros": {"texto": "Hola, los n칰meros son 1, 2, 3, 4, 5, 6, 7, 8, 9, 10", "audio": "static/audio/numeros.mp3", "imagenes": imagenes_fijas["n칰meros"]},
    "animales": {"texto": "Hola, los animales son perro, gato, elefante, le칩n, jirafa", "audio": "static/audio/animales.mp3", "imagenes": imagenes_fijas["animales"]},
    "frutas": {"texto": "Hola, las frutas son manzana, pl치tano, uva, fresa, sand칤a", "audio": "static/audio/frutas.mp3", "imagenes": imagenes_fijas["frutas"]},
    "formas": {"texto": "Hola, las formas son c칤rculo, cuadrado, tri치ngulo, rect치ngulo", "audio": "static/audio/formas.mp3", "imagenes": imagenes_fijas["formas"]}
}

# 3. FUNCIONES DE APOYO
def generar_audios_pregrabados(): 
    for clave, datos in respuestas_fijas.items(): 
        ruta_audio = datos["audio"] 
        if not os.path.exists(ruta_audio): 
            print(f"Generando audio para: {clave}") 
            tts = gTTS(datos["texto"], lang="es") 
            os.makedirs(os.path.dirname(ruta_audio), exist_ok=True) 
            tts.save(ruta_audio)


def obtener_respuesta_deepseek(pregunta, system_prompt="Eres un asistente amigable.", temperature=0.7):
    try:
        response = openai.ChatCompletion.create(
            model="deepseek-chat",
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": pregunta}],
            temperature=temperature, max_tokens=100
        )
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        return "Lo siento, tuve un problema. 쯄e repites?"

# 4. RUTAS (ENDPOINTS)
@app.route("/") 
def index(): 
    return render_template("index.html")

@app.route("/preguntar", methods=["POST"])
def preguntar():
    data = request.json
    pregunta = data.get("pregunta", "").strip().lower()
    
    # Buscar en fijas
    for clave in respuestas_fijas:
        if clave in pregunta:
            d = respuestas_fijas[clave]
            # Crear audio "Ahora dilo t칰"
            rep_name = f"rep_{uuid.uuid4()}.mp3"
            gTTS("Ahora dilo t칰.", lang="es").save(os.path.join(AUDIO_DIR, rep_name))
            return jsonify({"respuesta": d["texto"], "audio_url": "/" + d["audio"], "repetir_url": f"/static/audio/{rep_name}", "imagenes": d["imagenes"]})

    # Si no es fija, usar IA
    res_texto = obtener_respuesta_deepseek(pregunta)
    res_name = f"{uuid.uuid4()}.mp3"
    gTTS(res_texto, lang="es").save(os.path.join(AUDIO_DIR, res_name))
    
    rep_name = f"rep_{uuid.uuid4()}.mp3"
    gTTS("Ahora dilo t칰.", lang="es").save(os.path.join(AUDIO_DIR, rep_name))

    return jsonify({"respuesta": res_texto, "audio_url": f"/static/audio/{res_name}", "repetir_url": f"/static/audio/{rep_name}", "imagenes": []})


@app.route("/voz", methods=["POST"])
def voz():
    recognizer = sr.Recognizer()

    try:
        if "file" not in request.files:
            return jsonify({"texto": ""})

        file = request.files["file"]

        with tempfile.NamedTemporaryFile(delete=False, suffix=".tmp") as temp_input:
            file.save(temp_input.name)

        # Convertir con formato detectado
        audio = AudioSegment.from_file(temp_input.name)
        temp_wav_path = temp_input.name + ".wav"
        audio.export(temp_wav_path, format="wav")

        with sr.AudioFile(temp_wav_path) as source:
            audio_data = recognizer.record(source)

        texto = recognizer.recognize_google(audio_data, language="es-ES")

        print("Texto reconocido:", texto)

        return jsonify({"texto": texto})

    except sr.UnknownValueError:
        print("No se entendi칩 el audio")
        return jsonify({"texto": ""})

    except sr.RequestError as e:
        print("Error con Google STT:", e)
        return jsonify({"texto": ""})

    except Exception as e:
        print("Error general en voz:", repr(e))
        return jsonify({"texto": ""})

    finally:
        try:
            if os.path.exists(temp_input.name):
                os.remove(temp_input.name)
            if os.path.exists(temp_wav_path):
                os.remove(temp_wav_path)
        except:
            pass


@app.route("/validar", methods=["POST"])
def validar():
    data = request.json
    intento = data.get("intento", "").lower()
    correcta = data.get("respuesta", "").lower()
    
    prompt = "Eres un foniatra para ni침os. Si el ni침o dijo algo parecido a la respuesta, responde 'Muy bien'. Si no, an칤malo."
    try:
        res = openai.ChatCompletion.create(
            model="deepseek-chat",
            messages=[{"role": "system", "content": prompt}, {"role": "user", "content": f"Correcta: {correcta}. Ni침o dijo: {intento}"}],
            temperature=0.3
        )
        mensaje = res['choices'][0]['message']['content'].strip()
    except:
        mensaje = "춰Muy bien hecho!"

    audio_name = f"val_{uuid.uuid4()}.mp3"
    gTTS(mensaje, lang="es").save(os.path.join("static/audio", audio_name))
    
    # L칩gica de 칠xito para el frontend
    exito = any(palabra in mensaje.lower() for palabra in ["muy bien", "perfecto", "excelente", "correcto"])
    return jsonify({"mensaje": mensaje, "audio_url": f"/static/audio/{audio_name}", "correcto": exito})
    
# nuevoooooooo

@app.route("/oracion_vocal", methods=["POST"])
def oracion_vocal():
    data = request.json
    vocal = data.get("vocal", "").lower()

    if vocal not in ["a", "e", "i", "o", "u"]:
        return jsonify({"error": "Vocal inv치lida"}), 400

    prompt = f"""
    Genera:
    1) Una palabra infantil sencilla que empiece con la letra {vocal}.
    2) Una oraci칩n corta y f치cil para ni침os que incluya esa palabra.

    Responde SOLO en formato JSON as칤:
    {{
        "palabra_clave": "...",
        "oracion": "..."
    }}
    """

    try:
        response = openai.ChatCompletion.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "Eres un maestro de preescolar creativo."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.95,
            max_tokens=150
        )

        contenido = response['choices'][0]['message']['content'].strip()

        # 游댠 Limpieza por si DeepSeek responde con ```json
        if "```" in contenido:
            contenido = contenido.split("```")[1]
            contenido = contenido.replace("json", "").strip()

        resultado = json.loads(contenido)

        palabra = resultado["palabra_clave"].strip()
        oracion = resultado["oracion"].strip()

        # 游꿧 Crear audio autom치ticamente
        nombre_audio = f"oracion_{uuid.uuid4()}.mp3"
        ruta_audio = os.path.join(AUDIO_DIR, nombre_audio)

        tts = gTTS(oracion, lang="es")
        tts.save(ruta_audio)

        return jsonify({
            "palabra_clave": palabra,
            "oracion": oracion,
            "audio_url": f"/static/audio/{nombre_audio}"
        })

    except Exception as e:
        print("Error generando oraci칩n:", e)

        return jsonify({
            "palabra_clave": "Abeja",
            "oracion": "La abeja vuela en el jard칤n.",
            "audio_url": ""
        })
        

@app.route("/palabras_vocales", methods=["GET"])
def palabras_vocales():
    vocales = ["a", "e", "i", "o", "u"]
    palabras = []

    for vocal in vocales:
        palabra = generar_palabra_aleatoria(vocal)  # tu funci칩n IA
        palabras.append(palabra)

    return jsonify({"palabras": palabras})
    
def generar_palabra_aleatoria(vocal):
    prompt = f"""
    Dame una palabra infantil sencilla que empiece con la letra {vocal}.
    Responde SOLO la palabra.
    """

    try:
        response = openai.ChatCompletion.create(
            model="deepseek-chat",  # 游녣 sigues usando DeepSeek
            messages=[
                {"role": "system", "content": "Responde solo una palabra infantil."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.8,
            max_tokens=20
        )

        palabra = response['choices'][0]['message']['content'].strip()

        # limpieza por si responde algo extra
        palabra = palabra.replace('"', '').replace('.', '').split()[0]

        return palabra.capitalize()

    except Exception as e:
        print("Error generando palabra:", e)

        # respaldo si falla DeepSeek
        ejemplos = {
            "a": "Abeja",
            "e": "Elefante",
            "i": "Isla",
            "o": "Oso",
            "u": "Uva"
        }

        return ejemplos.get(vocal.lower(), "Abeja")

        
@app.route("/tts", methods=["POST"])
def tts():
    data = request.json
    texto = data.get("texto", "")

    if not texto:
        return jsonify({"error": "Texto vac칤o"}), 400

    try:
        nombre_audio = f"tts_{uuid.uuid4()}.mp3"
        ruta_audio = os.path.join(AUDIO_DIR, nombre_audio)

        tts = gTTS(texto, lang="es")
        tts.save(ruta_audio)

        return jsonify({"audio_url": f"/static/audio/{nombre_audio}"})
    except Exception as e:
        print("Error TTS:", e)
        return jsonify({"error": "Error generando audio"}), 500


# 5. INICIO DE LA APP
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host='0.0.0.0', port=port)


























